{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.1_LearningRate_PICCOLO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXNEBDSJ1dOvxGqTY4E/fc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloRusso137/3.1_Learning_rate_PICCOLO/blob/main/3_1_LearningRate_PICCOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFiQ6wff2NNM",
        "outputId": "b196960d-c634-4c49-8c93-8688e0bcd4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/PaoloRusso137/Project_DAAI.git\n",
        "#!mv \"/content/Project_DAAI\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB2iGA5swZ--",
        "outputId": "77ce8e4a-96c0-4348-b632-fc464eda1e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Project_DAAI' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/pitts30k.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XXNVKGE2q_z",
        "outputId": "d94375ac-d1ca-4a96-b226-22f2fbe29095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pitts30k/pitts30k  #Create a new folder called pitts30k inside the already existing pitts30k\n",
        "!mv \"/content/pitts30k/images\" \"/content/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "z_EkaaUU4uMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjgFJcWY4ePZ",
        "outputId": "100428d8-d4fc-44ab-81d1-5d0510598d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Project_DAAI\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8Gc237A4h6U",
        "outputId": "dde874de-d9ae-480d-8342-d48c17947cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project_DAAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss_cpu==1.7.1\n",
        "!pip install numpy==1.19.4\n",
        "!pip install Pillow==8.4.0\n",
        "!pip install scikit_learn==1.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install torchvision==0.8.1\n",
        "!pip install tqdm==4.48.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JWlZzmUT4pp6",
        "outputId": "b892e0c3-4dab-4a48-fc6c-3dc956aa72a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_cpu==1.7.1\n",
            "  Downloading faiss_cpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.1\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit_learn==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.1.0)\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.4)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.48.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir /content/pitts30k/pitts30k/pitts30k   #Create a new folder called pitts30k inside the already existing pitts30k"
      ],
      "metadata": {
        "id": "JovICVNW-hY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mv \"/content/pitts30k/pitts30k/images\" \"/content/pitts30k/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "CTdDQXGf_P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"train.py\" --datasets_folder \"/content/pitts30k/pitts30k\" --patience 2 --lr 0.000005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sN_7gjD5UMe",
        "outputId": "27f6a78e-bd92-4157-915f-bd764d8c3c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-06 08:25:08   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/pitts30k/pitts30k', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=5e-06, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-06_08-25-08', patience=2, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-06 08:25:08   The outputs are being saved in runs/default/2022-01-06_08-25-08\n",
            "2022-01-06 08:25:08   Using 1 GPUs and 2 CPUs\n",
            "2022-01-06 08:25:08   Loading dataset Pitts30k from folder /content/pitts30k/pitts30k\n",
            "2022-01-06 08:25:09   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-06 08:25:09   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
            "2022-01-06 08:25:09   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
            "2022-01-06 08:25:09   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 76.8MB/s]\n",
            "2022-01-06 08:25:10   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-06 08:25:12   Output dimension of the model is 256\n",
            "2022-01-06 08:25:12   Start training epoch: 00\n",
            "2022-01-06 08:25:12   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 782.53it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-06 08:32:53   Epoch[00](0/5): current batch triplet loss = 0.0656, average epoch triplet loss = 0.0718\n",
            "2022-01-06 08:32:53   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 798.81it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 08:40:31   Epoch[00](1/5): current batch triplet loss = 0.0802, average epoch triplet loss = 0.0691\n",
            "2022-01-06 08:40:31   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 792.09it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-06 08:48:10   Epoch[00](2/5): current batch triplet loss = 0.0564, average epoch triplet loss = 0.0663\n",
            "2022-01-06 08:48:10   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 797.61it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 08:55:50   Epoch[00](3/5): current batch triplet loss = 0.0693, average epoch triplet loss = 0.0643\n",
            "2022-01-06 08:55:50   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 832.74it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-06 09:03:33   Epoch[00](4/5): current batch triplet loss = 0.0703, average epoch triplet loss = 0.0631\n",
            "2022-01-06 09:03:33   Finished epoch 00 in 0:38:20, average epoch triplet loss = 0.0631\n",
            "2022-01-06 09:03:33   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.84it/s]\n",
            "2022-01-06 09:06:15   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.84it/s]\n",
            "2022-01-06 09:08:19   Calculating recalls\n",
            "2022-01-06 09:08:21   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 67.5, R@5: 84.0, R@10: 89.5, R@20: 93.5\n",
            "2022-01-06 09:08:21   Improved: previous best R@5 = 0.0, current R@5 = 84.0\n",
            "2022-01-06 09:08:21   Start training epoch: 01\n",
            "2022-01-06 09:08:21   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:59<00:00,  3.83it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 746.58it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 09:16:02   Epoch[01](0/5): current batch triplet loss = 0.0750, average epoch triplet loss = 0.0543\n",
            "2022-01-06 09:16:02   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.45it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 09:23:41   Epoch[01](1/5): current batch triplet loss = 0.0384, average epoch triplet loss = 0.0537\n",
            "2022-01-06 09:23:41   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 796.54it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 09:31:21   Epoch[01](2/5): current batch triplet loss = 0.0680, average epoch triplet loss = 0.0530\n",
            "2022-01-06 09:31:21   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 787.74it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-06 09:38:59   Epoch[01](3/5): current batch triplet loss = 0.0485, average epoch triplet loss = 0.0527\n",
            "2022-01-06 09:38:59   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 822.74it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 09:46:38   Epoch[01](4/5): current batch triplet loss = 0.0625, average epoch triplet loss = 0.0524\n",
            "2022-01-06 09:46:38   Finished epoch 01 in 0:38:17, average epoch triplet loss = 0.0524\n",
            "2022-01-06 09:46:38   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:41<00:00,  3.87it/s]\n",
            "2022-01-06 09:49:20   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.86it/s]\n",
            "2022-01-06 09:51:23   Calculating recalls\n",
            "2022-01-06 09:51:25   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 72.2, R@5: 87.7, R@10: 91.8, R@20: 94.9\n",
            "2022-01-06 09:51:25   Improved: previous best R@5 = 84.0, current R@5 = 87.7\n",
            "2022-01-06 09:51:25   Start training epoch: 02\n",
            "2022-01-06 09:51:25   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:01<00:00,  3.78it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 801.38it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-06 09:59:10   Epoch[02](0/5): current batch triplet loss = 0.0563, average epoch triplet loss = 0.0474\n",
            "2022-01-06 09:59:10   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 855.23it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:42<00:00,  1.13s/it]\n",
            "2022-01-06 10:06:51   Epoch[02](1/5): current batch triplet loss = 0.0299, average epoch triplet loss = 0.0475\n",
            "2022-01-06 10:06:51   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 831.37it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 10:14:29   Epoch[02](2/5): current batch triplet loss = 0.0213, average epoch triplet loss = 0.0472\n",
            "2022-01-06 10:14:29   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 829.43it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 10:22:07   Epoch[02](3/5): current batch triplet loss = 0.0294, average epoch triplet loss = 0.0463\n",
            "2022-01-06 10:22:07   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:59<00:00,  3.84it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 804.49it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-06 10:29:47   Epoch[02](4/5): current batch triplet loss = 0.0358, average epoch triplet loss = 0.0459\n",
            "2022-01-06 10:29:47   Finished epoch 02 in 0:38:21, average epoch triplet loss = 0.0459\n",
            "2022-01-06 10:29:47   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.85it/s]\n",
            "2022-01-06 10:32:29   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.84it/s]\n",
            "2022-01-06 10:34:33   Calculating recalls\n",
            "2022-01-06 10:34:35   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.5, R@5: 89.1, R@10: 92.9, R@20: 95.5\n",
            "2022-01-06 10:34:35   Improved: previous best R@5 = 87.7, current R@5 = 89.1\n",
            "2022-01-06 10:34:35   Start training epoch: 03\n",
            "2022-01-06 10:34:35   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:03<00:00,  3.74it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 780.86it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:45<00:00,  1.14s/it]\n",
            "2022-01-06 10:42:25   Epoch[03](0/5): current batch triplet loss = 0.0283, average epoch triplet loss = 0.0418\n",
            "2022-01-06 10:42:25   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:04<00:00,  3.73it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 787.86it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:47<00:00,  1.15s/it]\n",
            "2022-01-06 10:50:19   Epoch[03](1/5): current batch triplet loss = 0.0501, average epoch triplet loss = 0.0424\n",
            "2022-01-06 10:50:19   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 783.68it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 10:57:58   Epoch[03](2/5): current batch triplet loss = 0.0479, average epoch triplet loss = 0.0424\n",
            "2022-01-06 10:57:58   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:59<00:00,  3.84it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 797.85it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 11:05:39   Epoch[03](3/5): current batch triplet loss = 0.0713, average epoch triplet loss = 0.0421\n",
            "2022-01-06 11:05:39   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 818.70it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 11:13:19   Epoch[03](4/5): current batch triplet loss = 0.0505, average epoch triplet loss = 0.0418\n",
            "2022-01-06 11:13:19   Finished epoch 03 in 0:38:43, average epoch triplet loss = 0.0418\n",
            "2022-01-06 11:13:19   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:40<00:00,  3.89it/s]\n",
            "2022-01-06 11:15:59   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:02<00:00,  3.87it/s]\n",
            "2022-01-06 11:18:02   Calculating recalls\n",
            "2022-01-06 11:18:04   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.8, R@10: 93.5, R@20: 95.8\n",
            "2022-01-06 11:18:04   Improved: previous best R@5 = 89.1, current R@5 = 89.8\n",
            "2022-01-06 11:18:04   Start training epoch: 04\n",
            "2022-01-06 11:18:04   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:04<00:00,  3.74it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 735.57it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:47<00:00,  1.15s/it]\n",
            "2022-01-06 11:25:57   Epoch[04](0/5): current batch triplet loss = 0.0100, average epoch triplet loss = 0.0389\n",
            "2022-01-06 11:25:57   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 800.94it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 11:33:37   Epoch[04](1/5): current batch triplet loss = 0.0502, average epoch triplet loss = 0.0383\n",
            "2022-01-06 11:33:37   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 778.69it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 11:41:17   Epoch[04](2/5): current batch triplet loss = 0.0534, average epoch triplet loss = 0.0385\n",
            "2022-01-06 11:41:17   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 795.47it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:39<00:00,  1.12s/it]\n",
            "2022-01-06 11:48:56   Epoch[04](3/5): current batch triplet loss = 0.0380, average epoch triplet loss = 0.0388\n",
            "2022-01-06 11:48:56   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 776.33it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 11:56:35   Epoch[04](4/5): current batch triplet loss = 0.0308, average epoch triplet loss = 0.0385\n",
            "2022-01-06 11:56:35   Finished epoch 04 in 0:38:31, average epoch triplet loss = 0.0385\n",
            "2022-01-06 11:56:35   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:41<00:00,  3.87it/s]\n",
            "2022-01-06 11:59:17   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.84it/s]\n",
            "2022-01-06 12:01:21   Calculating recalls\n",
            "2022-01-06 12:01:22   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 77.1, R@5: 90.4, R@10: 93.9, R@20: 96.2\n",
            "2022-01-06 12:01:23   Improved: previous best R@5 = 89.8, current R@5 = 90.4\n",
            "2022-01-06 12:01:23   Start training epoch: 05\n",
            "2022-01-06 12:01:23   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:03<00:00,  3.76it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 772.09it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-06 12:09:11   Epoch[05](0/5): current batch triplet loss = 0.0265, average epoch triplet loss = 0.0382\n",
            "2022-01-06 12:09:11   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.78it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 730.36it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:50<00:00,  1.16s/it]\n",
            "2022-01-06 12:17:05   Epoch[05](1/5): current batch triplet loss = 0.0352, average epoch triplet loss = 0.0364\n",
            "2022-01-06 12:17:05   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.70it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-06 12:24:46   Epoch[05](2/5): current batch triplet loss = 0.0254, average epoch triplet loss = 0.0365\n",
            "2022-01-06 12:24:46   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.14it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:41<00:00,  1.13s/it]\n",
            "2022-01-06 12:32:26   Epoch[05](3/5): current batch triplet loss = 0.0136, average epoch triplet loss = 0.0361\n",
            "2022-01-06 12:32:26   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:55<00:00,  3.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 827.23it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 12:40:03   Epoch[05](4/5): current batch triplet loss = 0.0224, average epoch triplet loss = 0.0357\n",
            "2022-01-06 12:40:03   Finished epoch 05 in 0:38:40, average epoch triplet loss = 0.0357\n",
            "2022-01-06 12:40:03   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:39<00:00,  3.91it/s]\n",
            "2022-01-06 12:42:43   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:03<00:00,  3.87it/s]\n",
            "2022-01-06 12:44:46   Calculating recalls\n",
            "2022-01-06 12:44:48   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.0, R@5: 91.1, R@10: 94.2, R@20: 96.5\n",
            "2022-01-06 12:44:48   Improved: previous best R@5 = 90.4, current R@5 = 91.1\n",
            "2022-01-06 12:44:48   Start training epoch: 06\n",
            "2022-01-06 12:44:48   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.77it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 769.13it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:47<00:00,  1.15s/it]\n",
            "2022-01-06 12:52:40   Epoch[06](0/5): current batch triplet loss = 0.0558, average epoch triplet loss = 0.0356\n",
            "2022-01-06 12:52:40   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 869.46it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.13s/it]\n",
            "2022-01-06 13:00:23   Epoch[06](1/5): current batch triplet loss = 0.0146, average epoch triplet loss = 0.0350\n",
            "2022-01-06 13:00:23   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 852.71it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:45<00:00,  1.14s/it]\n",
            "2022-01-06 13:08:08   Epoch[06](2/5): current batch triplet loss = 0.0175, average epoch triplet loss = 0.0343\n",
            "2022-01-06 13:08:08   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 818.50it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:43<00:00,  1.14s/it]\n",
            "2022-01-06 13:15:52   Epoch[06](3/5): current batch triplet loss = 0.0308, average epoch triplet loss = 0.0345\n",
            "2022-01-06 13:15:52   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 817.67it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:45<00:00,  1.14s/it]\n",
            "2022-01-06 13:23:37   Epoch[06](4/5): current batch triplet loss = 0.0171, average epoch triplet loss = 0.0343\n",
            "2022-01-06 13:23:37   Finished epoch 06 in 0:38:48, average epoch triplet loss = 0.0343\n",
            "2022-01-06 13:23:37   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:42<00:00,  3.84it/s]\n",
            "2022-01-06 13:26:20   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:04<00:00,  3.83it/s]\n",
            "2022-01-06 13:28:24   Calculating recalls\n",
            "2022-01-06 13:28:25   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.1, R@5: 91.2, R@10: 94.3, R@20: 96.5\n",
            "2022-01-06 13:28:26   Improved: previous best R@5 = 91.1, current R@5 = 91.2\n",
            "2022-01-06 13:28:26   Start training epoch: 07\n",
            "2022-01-06 13:28:26   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:08<00:00,  3.66it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 729.16it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:53<00:00,  1.17s/it]\n",
            "2022-01-06 13:36:29   Epoch[07](0/5): current batch triplet loss = 0.0258, average epoch triplet loss = 0.0339\n",
            "2022-01-06 13:36:29   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 787.64it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 13:44:09   Epoch[07](1/5): current batch triplet loss = 0.0089, average epoch triplet loss = 0.0320\n",
            "2022-01-06 13:44:09   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 775.22it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 13:51:49   Epoch[07](2/5): current batch triplet loss = 0.0511, average epoch triplet loss = 0.0319\n",
            "2022-01-06 13:51:49   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 778.11it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:40<00:00,  1.12s/it]\n",
            "2022-01-06 13:59:29   Epoch[07](3/5): current batch triplet loss = 0.0235, average epoch triplet loss = 0.0320\n",
            "2022-01-06 13:59:29   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:58<00:00,  3.86it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 805.61it/s]\n",
            " 33%|████████████████████▎                                         | 82/250 [01:37<03:03,  1.09s/it]"
          ]
        }
      ]
    }
  ]
}