{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.1_Learning_rate_PICCOLO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcAlXXaG4A/VdgnYYC5M5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloRusso137/3.1_Learning_rate_PICCOLO/blob/main/3_1_Learning_rate_PICCOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcC5uP2FD7a4",
        "outputId": "61a48a35-7b99-4c4f-adfa-16bada9d3a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/PaoloRusso137/Project_DAAI.git"
      ],
      "metadata": {
        "id": "16wHSz0TEIX2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mv '/content/3.1_Learning_rate_PICCOLO' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "UwBoeBbGE7xs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/pitts30k.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhB-DckxESuW",
        "outputId": "ec03584b-a234-412c-b04a-c0d70252b9ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pitts30k/pitts30k  #Create a new folder called pitts30k inside the already existing pitts30k\n",
        "!mv \"/content/pitts30k/images\" \"/content/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "DMV6ExPaEpyD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydYsrV4gEq-4",
        "outputId": "47efbf02-4a31-48ca-c864-ca3746175727"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/3.1_Learning_rate_PICCOLO\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnJJcpPvFOC6",
        "outputId": "51660f28-4888-4e2b-9d78-f5c64527f5b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/3.1_Learning_rate_PICCOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss_cpu==1.7.1\n",
        "!pip install numpy==1.19.4\n",
        "!pip install Pillow==8.4.0\n",
        "!pip install scikit_learn==1.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install torchvision==0.8.1\n",
        "!pip install tqdm==4.48.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ai_sd6gxFT-y",
        "outputId": "280c6b59-fd07-4702-d18c-a821a67dcbc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_cpu==1.7.1\n",
            "  Downloading faiss_cpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.1\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit_learn==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.19.4)\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.4)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.4)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (8.4.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.48.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/pitts30k/pitts30k/pitts30k   #Create a new folder called pitts30k inside the already existing pitts30k\n",
        "!mv \"/content/pitts30k/pitts30k/images\" \"/content/pitts30k/pitts30k/pitts30k\" #The train file requires two folder named pitts30k"
      ],
      "metadata": {
        "id": "BkR3sxYVGZnB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"train.py\" --datasets_folder \"/content/pitts30k/pitts30k\" --patience 2 --lr 0.000005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqyOzn0tGR5S",
        "outputId": "08144ff4-2688-4b28-8a44-0c4b68443443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-08 09:57:13   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/pitts30k/pitts30k', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=5e-06, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-08_09-57-13', patience=2, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-08 09:57:13   The outputs are being saved in runs/default/2022-01-08_09-57-13\n",
            "2022-01-08 09:57:13   Using 1 GPUs and 2 CPUs\n",
            "2022-01-08 09:57:13   Loading dataset Pitts30k from folder /content/pitts30k/pitts30k\n",
            "2022-01-08 09:57:14   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-08 09:57:14   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
            "2022-01-08 09:57:14   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
            "2022-01-08 09:57:14   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 150MB/s]\n",
            "2022-01-08 09:57:15   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-08 09:57:17   Output dimension of the model is 256\n",
            "2022-01-08 09:57:17   Start training epoch: 00\n",
            "2022-01-08 09:57:17   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:15<00:00,  3.52it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 801.02it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:12<00:00,  1.25s/it]\n",
            "2022-01-08 10:05:47   Epoch[00](0/5): current batch triplet loss = 0.0656, average epoch triplet loss = 0.0718\n",
            "2022-01-08 10:05:47   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:13<00:00,  3.55it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 756.96it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 10:14:11   Epoch[00](1/5): current batch triplet loss = 0.0802, average epoch triplet loss = 0.0691\n",
            "2022-01-08 10:14:11   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.49it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 10:22:36   Epoch[00](2/5): current batch triplet loss = 0.0564, average epoch triplet loss = 0.0663\n",
            "2022-01-08 10:22:36   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 804.34it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 10:31:01   Epoch[00](3/5): current batch triplet loss = 0.0693, average epoch triplet loss = 0.0643\n",
            "2022-01-08 10:31:01   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 801.12it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.23s/it]\n",
            "2022-01-08 10:39:25   Epoch[00](4/5): current batch triplet loss = 0.0703, average epoch triplet loss = 0.0631\n",
            "2022-01-08 10:39:25   Finished epoch 00 in 0:42:08, average epoch triplet loss = 0.0631\n",
            "2022-01-08 10:39:25   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:56<00:00,  3.53it/s]\n",
            "2022-01-08 10:42:22   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:15<00:00,  3.52it/s]\n",
            "2022-01-08 10:44:38   Calculating recalls\n",
            "2022-01-08 10:44:39   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 67.5, R@5: 84.0, R@10: 89.5, R@20: 93.5\n",
            "2022-01-08 10:44:40   Improved: previous best R@5 = 0.0, current R@5 = 84.0\n",
            "2022-01-08 10:44:40   Start training epoch: 01\n",
            "2022-01-08 10:44:40   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:18<00:00,  3.47it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 790.19it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:14<00:00,  1.26s/it]\n",
            "2022-01-08 10:53:13   Epoch[01](0/5): current batch triplet loss = 0.0750, average epoch triplet loss = 0.0543\n",
            "2022-01-08 10:53:13   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 800.31it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 11:01:38   Epoch[01](1/5): current batch triplet loss = 0.0384, average epoch triplet loss = 0.0537\n",
            "2022-01-08 11:01:38   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.55it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 813.44it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 11:10:03   Epoch[01](2/5): current batch triplet loss = 0.0680, average epoch triplet loss = 0.0530\n",
            "2022-01-08 11:10:03   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 804.83it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.23s/it]\n",
            "2022-01-08 11:18:27   Epoch[01](3/5): current batch triplet loss = 0.0485, average epoch triplet loss = 0.0527\n",
            "2022-01-08 11:18:27   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.53it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.43it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.24s/it]\n",
            "2022-01-08 11:26:52   Epoch[01](4/5): current batch triplet loss = 0.0625, average epoch triplet loss = 0.0524\n",
            "2022-01-08 11:26:52   Finished epoch 01 in 0:42:12, average epoch triplet loss = 0.0524\n",
            "2022-01-08 11:26:52   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:57<00:00,  3.53it/s]\n",
            "2022-01-08 11:29:49   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:15<00:00,  3.52it/s]\n",
            "2022-01-08 11:32:04   Calculating recalls\n",
            "2022-01-08 11:32:06   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 72.2, R@5: 87.7, R@10: 91.8, R@20: 94.9\n",
            "2022-01-08 11:32:06   Improved: previous best R@5 = 84.0, current R@5 = 87.7\n",
            "2022-01-08 11:32:06   Start training epoch: 02\n",
            "2022-01-08 11:32:06   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:16<00:00,  3.50it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.43it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:10<00:00,  1.24s/it]\n",
            "2022-01-08 11:40:34   Epoch[02](0/5): current batch triplet loss = 0.0563, average epoch triplet loss = 0.0474\n",
            "2022-01-08 11:40:34   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 796.05it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 11:49:00   Epoch[02](1/5): current batch triplet loss = 0.0299, average epoch triplet loss = 0.0475\n",
            "2022-01-08 11:49:00   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 808.36it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.23s/it]\n",
            "2022-01-08 11:57:24   Epoch[02](2/5): current batch triplet loss = 0.0213, average epoch triplet loss = 0.0472\n",
            "2022-01-08 11:57:24   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 809.32it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 12:05:50   Epoch[02](3/5): current batch triplet loss = 0.0294, average epoch triplet loss = 0.0463\n",
            "2022-01-08 12:05:50   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.53it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 787.39it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 12:14:16   Epoch[02](4/5): current batch triplet loss = 0.0358, average epoch triplet loss = 0.0459\n",
            "2022-01-08 12:14:16   Finished epoch 02 in 0:42:09, average epoch triplet loss = 0.0459\n",
            "2022-01-08 12:14:16   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:56<00:00,  3.53it/s]\n",
            "2022-01-08 12:17:13   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:15<00:00,  3.52it/s]\n",
            "2022-01-08 12:19:28   Calculating recalls\n",
            "2022-01-08 12:19:29   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.5, R@5: 89.1, R@10: 92.9, R@20: 95.5\n",
            "2022-01-08 12:19:30   Improved: previous best R@5 = 87.7, current R@5 = 89.1\n",
            "2022-01-08 12:19:30   Start training epoch: 03\n",
            "2022-01-08 12:19:30   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:15<00:00,  3.52it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 808.67it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:11<00:00,  1.25s/it]\n",
            "2022-01-08 12:27:58   Epoch[03](0/5): current batch triplet loss = 0.0283, average epoch triplet loss = 0.0418\n",
            "2022-01-08 12:27:58   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 798.23it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 12:36:23   Epoch[03](1/5): current batch triplet loss = 0.0501, average epoch triplet loss = 0.0424\n",
            "2022-01-08 12:36:23   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 800.13it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 12:44:48   Epoch[03](2/5): current batch triplet loss = 0.0479, average epoch triplet loss = 0.0424\n",
            "2022-01-08 12:44:48   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 770.11it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 12:53:13   Epoch[03](3/5): current batch triplet loss = 0.0713, average epoch triplet loss = 0.0421\n",
            "2022-01-08 12:53:13   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.63it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:10<00:00,  1.24s/it]\n",
            "2022-01-08 13:01:39   Epoch[03](4/5): current batch triplet loss = 0.0505, average epoch triplet loss = 0.0418\n",
            "2022-01-08 13:01:39   Finished epoch 03 in 0:42:09, average epoch triplet loss = 0.0418\n",
            "2022-01-08 13:01:39   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:56<00:00,  3.53it/s]\n",
            "2022-01-08 13:04:36   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:14<00:00,  3.53it/s]\n",
            "2022-01-08 13:06:51   Calculating recalls\n",
            "2022-01-08 13:06:53   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.8, R@10: 93.5, R@20: 95.8\n",
            "2022-01-08 13:06:53   Improved: previous best R@5 = 89.1, current R@5 = 89.8\n",
            "2022-01-08 13:06:53   Start training epoch: 04\n",
            "2022-01-08 13:06:53   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:15<00:00,  3.52it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 803.86it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:11<00:00,  1.25s/it]\n",
            "2022-01-08 13:15:21   Epoch[04](0/5): current batch triplet loss = 0.0100, average epoch triplet loss = 0.0389\n",
            "2022-01-08 13:15:21   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 803.31it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.24s/it]\n",
            "2022-01-08 13:23:45   Epoch[04](1/5): current batch triplet loss = 0.0502, average epoch triplet loss = 0.0383\n",
            "2022-01-08 13:23:45   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:15<00:00,  3.53it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 792.41it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 13:32:11   Epoch[04](2/5): current batch triplet loss = 0.0534, average epoch triplet loss = 0.0385\n",
            "2022-01-08 13:32:11   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 806.04it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 13:40:36   Epoch[04](3/5): current batch triplet loss = 0.0380, average epoch triplet loss = 0.0388\n",
            "2022-01-08 13:40:36   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 811.31it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:08<00:00,  1.24s/it]\n",
            "2022-01-08 13:49:00   Epoch[04](4/5): current batch triplet loss = 0.0308, average epoch triplet loss = 0.0385\n",
            "2022-01-08 13:49:00   Finished epoch 04 in 0:42:06, average epoch triplet loss = 0.0385\n",
            "2022-01-08 13:49:00   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:57<00:00,  3.52it/s]\n",
            "2022-01-08 13:51:58   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:15<00:00,  3.52it/s]\n",
            "2022-01-08 13:54:13   Calculating recalls\n",
            "2022-01-08 13:54:15   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 77.1, R@5: 90.4, R@10: 93.9, R@20: 96.2\n",
            "2022-01-08 13:54:15   Improved: previous best R@5 = 89.8, current R@5 = 90.4\n",
            "2022-01-08 13:54:15   Start training epoch: 05\n",
            "2022-01-08 13:54:15   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:17<00:00,  3.49it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 721.97it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:12<00:00,  1.25s/it]\n",
            "2022-01-08 14:02:46   Epoch[05](0/5): current batch triplet loss = 0.0265, average epoch triplet loss = 0.0382\n",
            "2022-01-08 14:02:46   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:16<00:00,  3.49it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 718.71it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:14<00:00,  1.26s/it]\n",
            "2022-01-08 14:11:18   Epoch[05](1/5): current batch triplet loss = 0.0352, average epoch triplet loss = 0.0364\n",
            "2022-01-08 14:11:18   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 716.39it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 14:19:43   Epoch[05](2/5): current batch triplet loss = 0.0254, average epoch triplet loss = 0.0365\n",
            "2022-01-08 14:19:43   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.53it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 704.82it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 14:28:09   Epoch[05](3/5): current batch triplet loss = 0.0136, average epoch triplet loss = 0.0361\n",
            "2022-01-08 14:28:09   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 797.57it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 14:36:34   Epoch[05](4/5): current batch triplet loss = 0.0224, average epoch triplet loss = 0.0357\n",
            "2022-01-08 14:36:34   Finished epoch 05 in 0:42:18, average epoch triplet loss = 0.0357\n",
            "2022-01-08 14:36:34   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:56<00:00,  3.54it/s]\n",
            "2022-01-08 14:39:30   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 476/476 [02:14<00:00,  3.53it/s]\n",
            "2022-01-08 14:41:45   Calculating recalls\n",
            "2022-01-08 14:41:47   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 78.0, R@5: 91.1, R@10: 94.2, R@20: 96.5\n",
            "2022-01-08 14:41:47   Improved: previous best R@5 = 90.4, current R@5 = 91.1\n",
            "2022-01-08 14:41:47   Start training epoch: 06\n",
            "2022-01-08 14:41:47   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:16<00:00,  3.51it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 724.79it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 14:50:14   Epoch[06](0/5): current batch triplet loss = 0.0558, average epoch triplet loss = 0.0356\n",
            "2022-01-08 14:50:14   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 789.89it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:09<00:00,  1.24s/it]\n",
            "2022-01-08 14:58:39   Epoch[06](1/5): current batch triplet loss = 0.0146, average epoch triplet loss = 0.0350\n",
            "2022-01-08 14:58:39   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:14<00:00,  3.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 815.50it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:10<00:00,  1.24s/it]\n",
            "2022-01-08 15:07:05   Epoch[06](2/5): current batch triplet loss = 0.0175, average epoch triplet loss = 0.0343\n",
            "2022-01-08 15:07:05   Cache: 3 / 5\n",
            " 19%|███████████▌                                                 | 130/688 [00:38<02:35,  3.58it/s]"
          ]
        }
      ]
    }
  ]
}